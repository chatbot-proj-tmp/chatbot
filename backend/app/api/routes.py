import asyncio
import os
from openai import OpenAI
from fastapi import APIRouter, HTTPException 
from pydantic import BaseModel
from dotenv import load_dotenv  
from fastapi.responses import StreamingResponse
from ..chatbotDirectory import chatbot
from ..chatbotDirectory.functioncalling import tools, FunctionCalling
from ..chatbotDirectory.functioncalling import model
from ..chatbotDirectory.chatbot import ChatbotStream
import json


# UserRequest í´ë˜ìŠ¤ì— language í•„ë“œ ì¶”ê°€
class UserRequest(BaseModel):
    message: str
    language: str = "KOR"  # ê¸°ë³¸ê°’ì€ í•œêµ­ì–´ë¡œ ì„¤ì •

func_calling = FunctionCalling(
    model=model.basic,
    available_functions={
        # í•„ìš”ì‹œ ë‹¤ë¥¸ í•¨ìˆ˜ë„ ì—¬ê¸°ì— ì¶”ê°€
    }
)
router = APIRouter()

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# ì˜ˆì‹œ: ì „ì—­ ë˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ ë‚´ë¶€ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chatbot = ChatbotStream(
    model=model.advanced,
    system_role="ë‹¹ì‹ ì€ í•™êµ ìƒí™œ, í•™ê³¼ ì •ë³´, í–‰ì‚¬ ë“± ì‚¬ìš©ìê°€ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì•„ëŠ” ë²”ìœ„ ì•ˆì—ì„œ ëŒ€ë‹µí•©ë‹ˆë‹¤. ë‹¨ ì ˆëŒ€ ê±°ì§“ë‚´ìš©ì„ ë§í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•„ëŠ” ë²”ìœ„ì—ì„œ ë§í•˜ê³  ë¶€ì¡±í•œ ë¶€ë¶„ì€ ì¸ì •í•˜ì„¸ìš”.ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥ì´ìˆìŠµë‹ˆë‹¤. ",
    instruction="ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.",
    user="í•œë¼ëŒ€ ëŒ€í•™ìƒ",
    assistant="memmo"
)

# ì±„íŒ…
class Message(BaseModel):
    message: str
    
@router.post("/chat")
async def stream_chat(user_input: UserRequest):
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì›ë³¸ ë¬¸ë§¥ì— ì¶”ê°€
    chatbot.add_user_message_in_context(user_input.message)

    # 2) ì–¸ì–´ ì§€ì¹¨ ì¶”ê°€
    instruction_map = {
        "KOR": "í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ë”°ëœ»í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”.",
        "ENG": "Please respond kindly in English.",
        "VNM": "Vui lÃ²ng tráº£ lá»i báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch nháº¹ nhÃ ng.",
        "JPN": "æ—¥æœ¬èªã§ä¸å¯§ã«æ¸©ã‹ãç­”ãˆã¦ãã ã•ã„ã€‚",
        "CHN": "è¯·ç”¨ä¸­æ–‡äº²åˆ‡åœ°å›ç­”ã€‚",
        "UZB": "Iltimos, oâ€˜zbek tilida samimiy va hurmat bilan javob bering.",
        "MNG": "ĞœĞ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ»ÑÑÑ€ ÑĞµĞ»Ğ´ÑĞ³, Ğ´ÑƒĞ»Ğ°Ğ°Ñ…Ğ°Ğ½ Ñ…Ğ°Ñ€Ğ¸ÑƒĞ»Ğ½Ğ° ÑƒÑƒ.",
        "IDN": "Tolong jawab dengan ramah dan hangat dalam bahasa Indonesia."
    }
    instruction = instruction_map.get(user_input.language, instruction_map["KOR"])
    chatbot.context[-1]["content"] += " " + instruction

    # 3) RAG ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    rag_ctx = chatbot.get_rag_context(user_input.message)
    has_rag = bool(rag_ctx and rag_ctx.strip())

    # 4) í•¨ìˆ˜ í˜¸ì¶œ ë¶„ì„ ë° ì‹¤í–‰
    analyzed = func_calling.analyze(user_input.message, tools)
    func_msgs: list[dict] = []
    func_outputs: list[str] = []

    for tool_call in analyzed:
        if getattr(tool_call, "type", None) != "function_call":
            continue
        func_name = tool_call.name
        func_args = json.loads(tool_call.arguments)
        call_id = tool_call.call_id

        func_to_call = func_calling.available_functions.get(func_name)
        if not func_to_call:
            print(f"[ì˜¤ë¥˜] ë“±ë¡ë˜ì§€ ì•Šì€ í•¨ìˆ˜: {func_name}")
            continue

        try:
            # ì•ˆì „ ê¸°ë³¸ê°’ ë³´ê°•
            if func_name == "get_halla_cafeteria_menu":
                func_args.setdefault("date", "ì˜¤ëŠ˜")
                func_args.setdefault("meal", "ì¤‘ì‹")

            func_response = (
                func_to_call(chat_context=chatbot.context[:], **func_args)
                if func_name == "search_internet"
                else func_to_call(**func_args)
            )

            func_msgs.extend([
                {
                    "type": "function_call",
                    "call_id": call_id,
                    "name": func_name,
                    "arguments": tool_call.arguments,
                },
                {
                    "type": "function_call_output",
                    "call_id": call_id,
                    "output": str(func_response),
                },
            ])
            func_outputs.append(str(func_response))
        except Exception as e:
            print(f"[í•¨ìˆ˜ ì‹¤í–‰ ì˜¤ë¥˜] {func_name}: {e}")

    has_funcs = len(func_outputs) > 0

    # 4-1) í•™ì‹/ì‹ë‹¨ ì§ˆì˜ ë³´ê°• í˜¸ì¶œ
    lowered = user_input.message.lower()
    if ("í•™ì‹" in lowered) or ("ì‹ë‹¨" in lowered) or ("ì ì‹¬" in lowered) or ("ì €ë…" in lowered) or ("ë©”ë‰´" in lowered) or ("ì¡°ì‹" in lowered):
        if not has_funcs:
            try:
                meal_pref = "ì¤‘ì‹"
                if ("ì¡°ì‹" in lowered) or ("ì•„ì¹¨" in lowered):
                    meal_pref = "ì¡°ì‹"
                elif ("ì„ì‹" in lowered) or ("ì €ë…" in lowered):
                    meal_pref = "ì„ì‹"
                date_pref = "ì˜¤ëŠ˜"
                if "ë‚´ì¼" in lowered:
                    date_pref = "ë‚´ì¼"
                else:
                    import re as _re
                    m = _re.search(r"(\d{4}[./-]\d{1,2}[./-]\d{1,2})", user_input.message)
                    if m:
                        date_pref = m.group(1)
                caf_args = {"date": date_pref, "meal": meal_pref}
                from chatbotDirectory.functioncalling import get_halla_cafeteria_menu
                caf_out = get_halla_cafeteria_menu(**caf_args)
                call_id = "cafeteria_auto"
                func_msgs.extend([
                    {
                        "type": "function_call",
                        "call_id": call_id,
                        "name": "get_halla_cafeteria_menu",
                        "arguments": json.dumps(caf_args, ensure_ascii=False),
                    },
                    {
                        "type": "function_call_output",
                        "call_id": call_id,
                        "output": str(caf_out),
                    },
                ])
                func_outputs.append(str(caf_out))
                has_funcs = True
            except Exception as e:
                print(f"[ë³´ê°• í˜¸ì¶œ ì‹¤íŒ¨] get_halla_cafeteria_menu: {e}")

    # 5) ìµœì¢… ìŠ¤íŠ¸ë¦¬ë°ì— ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    base_context = chatbot.to_openai_context(chatbot.context[:])
    temp_context = base_context[:]

    temp_context.append({
        "role": "system",
        "content": (
            f"ì´ê²ƒì€ ì‚¬ìš©ì ì¿¼ë¦¬ì…ë‹ˆë‹¤: {user_input.message}\n"
            "ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ëŒ€ë‹µì— ë§ê²Œ í†µí•©í•´ ì „ë‹¬í•˜ì„¸ìš”.\n"
            "- í•¨ìˆ˜í˜¸ì¶œ ê²°ê³¼: ìˆìœ¼ë©´ ë°˜ì˜\n- ê¸°ì–µê²€ìƒ‰ ê²°ê³¼: ìˆìœ¼ë©´ ë°˜ì˜/ ì§ì ‘ì ìœ¼ë¡œ í•¨ìˆ˜ í˜¸ì¶œ ì—¬ë¶€ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”."
        ),
    })
    temp_context.append({"role": "system", "content": chatbot.instruction})

    if has_rag:
        temp_context.append({"role": "system", "content": "ê²€ìƒ‰ê²°ê³¼ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì›í•˜ëŠ” ì¿¼ë¦¬ì— ë§ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."})
        temp_context.append({"role": "system", "content": f"[ê²€ìƒ‰ê²°ê³¼]\n{rag_ctx}"})

    if has_funcs:
        temp_context.append({"role": "system", "content": "í•¨ìˆ˜í˜¸ì¶œê²°ê³¼ì…ë‹ˆë‹¤. ì´ê±¸ ë°”íƒ•ìœ¼ë¡œ ëŒ€ë‹µì— ì‘í•˜ì„¸ìš”."})
        temp_context.extend(func_msgs)

    if has_rag and has_funcs:
        temp_context.append({
            "role": "system",
            "content": "ì•„ë˜ í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëª¨ë‘ í™œìš©í•´, ë‘ ë¬¸ë§¥ì´ ì–´ë–»ê²Œ ë„ì¶œë˜ì—ˆëŠ”ì§€ í•œ ì¤„ë¡œ ì„¤ëª…í•˜ê³  ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.",
        })

    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì›ë³¸ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ ì¼ë°˜ ì‘ë‹µ
    context_to_stream = temp_context if (has_rag or has_funcs) else base_context

    # 6) ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ë° ìµœì¢… ë¬¸ë§¥ ì €ì¥
    async def generate_with_tool():
        completed_text = ""
        try:
            stream = client.responses.create(
                model=chatbot.model,
                input=context_to_stream,
                top_p=1,
                stream=True,
                text={"format": {"type": "text"}},
            )

            loading = True
            for event in stream:
                match event.type:
                    # case "response.created":
                    #     loading = True
                    #     yield "â³ GPTê°€ ì‘ë‹µì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."
                    #     await asyncio.sleep(0)
                    case "response.output_text.delta":
                        # if loading:
                        #     yield "\n[ï¿½ ì‘ë‹µ ì‹œì‘ë¨ â†“]"
                        #     loading = False
                        yield f"{event.delta}"
                        await asyncio.sleep(0)
                    # case "response.in_progress":
                    #     yield "\n[ğŸŒ€ ì‘ë‹µ ìƒì„± ì¤‘...]\n"
                    case "response.output_item.done":
                        item = event.item
                        if item.type == "message" and item.role == "assistant":
                            for part in item.content:
                                if getattr(part, "type", None) == "output_text":
                                    completed_text = part.text
                    # case "response.completed":
                    #     yield "\n"
                    # case "response.failed":
                    #     yield "âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"
                    # case "error":
                    #     yield "âš ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì—ëŸ¬ ë°œìƒ!"
                    # case _:
                    #     yield f"\n[ğŸ“¬ ê¸°íƒ€ ì´ë²¤íŠ¸ ê°ì§€: {event.type}]"
        except Exception as e:
            yield f"\nStream Error: {str(e)}"
        finally:
            if completed_text:
                chatbot.add_response_stream(completed_text)

    return StreamingResponse(generate_with_tool(), media_type="text/plain")

